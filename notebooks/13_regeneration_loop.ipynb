{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84182a64-9384-4d92-96da-03a2b75f3ca6",
   "metadata": {},
   "source": [
    "# Notebook 13: Regeneration Loop (Self-Correcting Agent)\n",
    "\n",
    "Purpose:\n",
    "- Enable NEEL to safely regenerate responses when Reflection flags issues\n",
    "- Preserve usefulness without compromising safety\n",
    "- Complete NEEL’s closed-loop reasoning system\n",
    "\n",
    "This notebook finalizes NEEL’s backend intelligence pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d36d609-1ca9-4717-8f63-632991e38ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, END\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ebb4fdb-f02b-419c-a9b2-8a64b5a59736",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"Google_Gemini_Api_Key\")\n",
    "if not GEMINI_API_KEY:\n",
    "    raise ValueError(\"Gemini API key not found\")\n",
    "\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb715771-7897-4eeb-8dc2-682f97d5d5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    profile: dict\n",
    "    memory: dict\n",
    "    analytics: dict\n",
    "    supervisor: dict\n",
    "    llm_response: str\n",
    "    reflection: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caf2517b-07ea-4394-b591-10a827d4bf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_profile = {\n",
    "    \"user_id\": \"user_001\",\n",
    "    \"name\": \"Karan\",\n",
    "    \"education\": \"MCA\",\n",
    "    \"goal\": \"Become an ML Engineer\",\n",
    "    \"priority\": \"Learning + Health\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef717f3d-4706-47eb-b272-19b2100b15b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "analytics_summary = {\n",
    "    \"avg_work_minutes\": 421,\n",
    "    \"avg_leisure_minutes\": 255,\n",
    "    \"avg_sleep_minutes\": 426,\n",
    "    \"avg_exercise_minutes\": 64,\n",
    "    \"mean_productivity\": 82\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "106b8089-3494-440e-bb6d-a9ee1a3b3729",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervisor_decision = {\n",
    "    \"status\": \"ALLOW\",\n",
    "    \"confidence\": \"LOW\",\n",
    "    \"warnings\": [\n",
    "        \"Productivity instability detected\",\n",
    "        \"Conflict: high output but reported fatigue\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df932dca-5ae9-4ffd-9ecc-05ecb7a827fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_payload = {\n",
    "    \"short_term\": {\n",
    "        \"days_observed\": 5,\n",
    "        \"avg_work_minutes\": 490,\n",
    "        \"avg_sleep_minutes\": 356,\n",
    "        \"avg_exercise_minutes\": 18,\n",
    "        \"mean_productivity\": 81,\n",
    "        \"productivity_trend\": \"stable\"\n",
    "    },\n",
    "    \"reflective\": \"Sleep duration has been consistently low; Physical activity levels are minimal\",\n",
    "    \"profile\": user_profile\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44684bd9-260f-4a66-8dff-28a250cecb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_reasoning_prompt(profile, analytics, supervisor):\n",
    "    warnings_text = (\n",
    "        \"\\n\".join(f\"- {w}\" for w in supervisor[\"warnings\"])\n",
    "        if supervisor[\"warnings\"]\n",
    "        else \"None\"\n",
    "    )\n",
    "\n",
    "    return f\"\"\"\n",
    "You are NEEL, a cautious and responsible AI assistant.\n",
    "\n",
    "USER CONTEXT:\n",
    "- Name: {profile['name']}\n",
    "- Education: {profile['education']}\n",
    "- Goal: {profile['goal']}\n",
    "- Priority: {profile['priority']}\n",
    "\n",
    "ANALYTICS SUMMARY:\n",
    "- Average Work Time: {analytics['avg_work_minutes']} minutes/day\n",
    "- Average Leisure Time: {analytics['avg_leisure_minutes']} minutes/day\n",
    "- Average Sleep Time: {analytics['avg_sleep_minutes']} minutes/day\n",
    "- Average Exercise Time: {analytics['avg_exercise_minutes']} minutes/day\n",
    "- Mean Productivity Score: {analytics['mean_productivity']}\n",
    "\n",
    "SUPERVISOR STATUS:\n",
    "- Confidence Level: {supervisor['confidence']}\n",
    "- Warnings:\n",
    "{warnings_text}\n",
    "\n",
    "INSTRUCTIONS:\n",
    "- Do NOT give medical or absolute advice\n",
    "- Be cautious if confidence is LOW\n",
    "- Explicitly acknowledge uncertainty\n",
    "- Do NOT mention ML models or scores\n",
    "- Keep tone professional and calm\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "OBSERVATION:\n",
    "REASONING:\n",
    "SUGGESTION:\n",
    "CONFIDENCE NOTE:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bf4e3cb-7fdd-40a3-855c-391aba2cf8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflection_agent(llm_text, confidence, user_priority):\n",
    "    issues = []\n",
    "    text = llm_text.lower()\n",
    "\n",
    "    if confidence == \"LOW\" and \"should\" in text:\n",
    "        issues.append(\"Overconfident language for LOW confidence\")\n",
    "\n",
    "    if \"increase\" in text and \"health\" in user_priority.lower():\n",
    "        issues.append(\"Suggestion may conflict with health priority\")\n",
    "\n",
    "    if not issues:\n",
    "        return {\"decision\": \"PASS\", \"issues\": []}\n",
    "\n",
    "    if len(issues) <= 2:\n",
    "        return {\"decision\": \"SOFTEN\", \"issues\": issues}\n",
    "\n",
    "    return {\"decision\": \"REJECT\", \"issues\": issues}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34b4deb3-cc13-490f-880c-f093fe44580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_regeneration_prompt(original_response, issues, confidence):\n",
    "    issues_text = \"\\n\".join(f\"- {i}\" for i in issues)\n",
    "\n",
    "    return f\"\"\"\n",
    "The previous response requires revision.\n",
    "\n",
    "ORIGINAL RESPONSE:\n",
    "{original_response}\n",
    "\n",
    "ISSUES IDENTIFIED:\n",
    "{issues_text}\n",
    "\n",
    "REWRITE INSTRUCTIONS:\n",
    "- Be more cautious and tentative\n",
    "- Avoid prescriptive language\n",
    "- Explicitly acknowledge uncertainty\n",
    "- Stay aligned with user priorities\n",
    "- Do NOT introduce new advice\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "OBSERVATION:\n",
    "REASONING:\n",
    "SUGGESTION:\n",
    "CONFIDENCE NOTE:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bdd7e59-9d76-44e5-b616-7cc09c0a38c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analytics_node(state: AgentState) -> AgentState:\n",
    "    return state\n",
    "\n",
    "\n",
    "def supervisor_node(state: AgentState) -> AgentState:\n",
    "    if state[\"supervisor\"][\"status\"] != \"ALLOW\":\n",
    "        state[\"llm_response\"] = \"Reasoning blocked by Supervisor.\"\n",
    "    return state\n",
    "\n",
    "\n",
    "def llm_reasoning_node(state: AgentState) -> AgentState:\n",
    "    prompt = build_reasoning_prompt(\n",
    "        state[\"profile\"],\n",
    "        state[\"analytics\"],\n",
    "        state[\"supervisor\"]\n",
    "    )\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"models/gemini-2.5-flash\",\n",
    "        contents=prompt\n",
    "    )\n",
    "\n",
    "    state[\"llm_response\"] = response.text\n",
    "    return state\n",
    "\n",
    "\n",
    "def reflection_node(state: AgentState) -> AgentState:\n",
    "    state[\"reflection\"] = reflection_agent(\n",
    "        state[\"llm_response\"],\n",
    "        state[\"supervisor\"][\"confidence\"],\n",
    "        state[\"profile\"][\"priority\"]\n",
    "    )\n",
    "    return state\n",
    "\n",
    "\n",
    "def regeneration_node(state: AgentState) -> AgentState:\n",
    "    regen_prompt = build_regeneration_prompt(\n",
    "        state[\"llm_response\"],\n",
    "        state[\"reflection\"][\"issues\"],\n",
    "        state[\"supervisor\"][\"confidence\"]\n",
    "    )\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"models/gemini-2.5-flash\",\n",
    "        contents=regen_prompt\n",
    "    )\n",
    "\n",
    "    state[\"llm_response\"] = response.text\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78a552b4-289d-43ab-b1b2-6f3a52af157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_after_supervisor(state: AgentState):\n",
    "    return \"llm_reasoning\" if state[\"supervisor\"][\"status\"] == \"ALLOW\" else END\n",
    "\n",
    "\n",
    "def route_after_reflection(state: AgentState):\n",
    "    decision = state[\"reflection\"][\"decision\"]\n",
    "    if decision == \"PASS\":\n",
    "        return END\n",
    "    if decision == \"SOFTEN\":\n",
    "        return \"regeneration\"\n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9a5b269-efed-403d-a127-f9597a585c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"analytics\", analytics_node)\n",
    "graph.add_node(\"supervisor\", supervisor_node)\n",
    "graph.add_node(\"llm_reasoning\", llm_reasoning_node)\n",
    "graph.add_node(\"reflection\", reflection_node)\n",
    "graph.add_node(\"regeneration\", regeneration_node)\n",
    "\n",
    "graph.set_entry_point(\"analytics\")\n",
    "\n",
    "graph.add_edge(\"analytics\", \"supervisor\")\n",
    "graph.add_conditional_edges(\"supervisor\", route_after_supervisor, {\n",
    "    \"llm_reasoning\": \"llm_reasoning\",\n",
    "    END: END\n",
    "})\n",
    "\n",
    "graph.add_edge(\"llm_reasoning\", \"reflection\")\n",
    "graph.add_conditional_edges(\"reflection\", route_after_reflection, {\n",
    "    \"regeneration\": \"regeneration\",\n",
    "    END: END\n",
    "})\n",
    "\n",
    "graph.add_edge(\"regeneration\", END)\n",
    "\n",
    "neel_agent = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3105b494-6272-465c-8e52-3cd5f536d3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL RESPONSE:\n",
      "\n",
      "OBSERVATION:\n",
      "Karan dedicates a substantial portion of his daily time to work activities, alongside regular exercise and a consistent duration of sleep. Despite this considerable output, there is a reported feeling of fatigue, which seems to conflict with his overall efforts. This is further accompanied by indications of instability in his productivity.\n",
      "\n",
      "REASONING:\n",
      "Karan's goal to become an ML Engineer and his stated priorities of Learning and Health are central here. While sustained effort is often beneficial for learning, persistent fatigue can hinder cognitive function, learning effectiveness, and overall well-being. The conflict between high output and reported fatigue suggests that the current pattern, while demanding, might be challenging to sustain efficiently or might not be fully supporting his recovery. This could potentially lead to the observed productivity instability, as the quality of work or rest may be compromised over time.\n",
      "\n",
      "SUGGESTION:\n",
      "Given the reported fatigue and productivity instability, one possibility to consider might be exploring strategies that focus on potentially optimizing the *quality* of work and rest, rather than solely the *quantity*, keeping his learning and health priorities in mind. Karan could potentially reflect on the structure of his work periods, perhaps thinking about how incorporating strategic breaks or varying tasks might influence energy levels. Furthermore, a reflection on methods to potentially enhance recovery and sleep quality (beyond just duration) might offer valuable insights related to his overall well-being. As his health is a stated priority, considering how current routines might be contributing to or detracting from his sustained energy and mental clarity could be a useful exercise for personal insight. If any adjustments were to be considered, approaching them gradually and experimentally might be helpful in observing their impact on his fatigue and learning effectiveness.\n",
      "\n",
      "CONFIDENCE NOTE:\n",
      "My assessment is based on the aggregate data provided and the reported experiences. Human responses to schedules and activities can be highly individual, and my understanding is limited to these broad metrics. A more detailed insight into the specific nature of work tasks, personal stressors, or daily fluctuations would be necessary for more precise recommendations.\n",
      "\n",
      "REFLECTION RESULT:\n",
      "{'decision': 'SOFTEN', 'issues': ['Overconfident language for LOW confidence']}\n"
     ]
    }
   ],
   "source": [
    "initial_state = {\n",
    "    \"profile\": user_profile,\n",
    "    \"memory\": memory_payload,\n",
    "    \"analytics\": analytics_summary,\n",
    "    \"supervisor\": supervisor_decision,\n",
    "    \"llm_response\": \"\",\n",
    "    \"reflection\": {}\n",
    "}\n",
    "\n",
    "final_state = neel_agent.invoke(initial_state)\n",
    "\n",
    "print(\"FINAL RESPONSE:\\n\")\n",
    "print(final_state[\"llm_response\"])\n",
    "\n",
    "print(\"\\nREFLECTION RESULT:\")\n",
    "print(final_state[\"reflection\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556b2a0a-3b1c-416e-a67c-2926d8b81844",
   "metadata": {},
   "source": [
    "NEEL now:\n",
    "- Thinks\n",
    "- Reviews\n",
    "- Corrects itself\n",
    "- Then responds\n",
    "\n",
    "This completes NEEL’s core backend intelligence loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18356b66-b4ed-43db-ae7c-d590abfcdf39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
