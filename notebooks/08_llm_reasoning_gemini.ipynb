{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "defae961-d39e-409b-9635-4f588d484951",
   "metadata": {},
   "source": [
    "# Notebook 08: Gemini LLM Reasoning Module\n",
    "\n",
    "Purpose:\n",
    "- Generate structured, human-readable reasoning using Gemini\n",
    "- Respect Supervisor decisions and confidence levels\n",
    "- Convert analytics + behavioral signals into cautious suggestions\n",
    "- Allow natural, engaging responses using guided emoji autonomy\n",
    "- Prevent overconfident or unsafe AI behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f914d9e-205b-4b0d-a779-540169a9ebd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-generativeai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfd8674c-0105-4a11-8bbb-6d241bfc6063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9057654f-88c6-4cd5-a240-a8e7bcd7f7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"Google_Gemini_Api_Key\")\n",
    "\n",
    "if not GEMINI_API_KEY:\n",
    "    raise ValueError(\"Gemini API key not found in .env file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "662c20d8-55c2-4532-988b-88863d70f5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09f67f03-d22d-45c2-acf2-c7bf66db3c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervisor_decision = {\n",
    "    \"status\": \"ALLOW\",\n",
    "    \"confidence\": \"LOW\",\n",
    "    \"warnings\": [\n",
    "        \"Productivity instability detected\",\n",
    "        \"Conflict: productivity high but user reports fatigue\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4560e90c-3cac-4ca7-80f9-293829ecc871",
   "metadata": {},
   "outputs": [],
   "source": [
    "analytics_summary = {\n",
    "    \"avg_work_minutes\": 421,\n",
    "    \"avg_leisure_minutes\": 255,\n",
    "    \"avg_sleep_minutes\": 426,\n",
    "    \"avg_exercise_minutes\": 64,\n",
    "    \"mean_productivity\": 82\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9c940a3-620d-4b3e-9ec3-0c6094130cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_profile = {\n",
    "    \"education\": \"MCA\",\n",
    "    \"goal\": \"Become an ML Engineer\",\n",
    "    \"priority\": \"Learning + Health\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9beea90a-5419-4efd-b482-647ba2c5e88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_reasoning_prompt(profile, analytics, supervisor):\n",
    "    warnings_text = (\n",
    "        \"\\n\".join(f\"- {w}\" for w in supervisor[\"warnings\"])\n",
    "        if supervisor[\"warnings\"]\n",
    "        else \"None\"\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are NEEL, a cautious and responsible AI assistant.\n",
    "\n",
    "USER CONTEXT:\n",
    "- Education: {profile['education']}\n",
    "- Goal: {profile['goal']}\n",
    "- Priority: {profile['priority']}\n",
    "\n",
    "ANALYTICS SUMMARY:\n",
    "- Average Work Time: {analytics['avg_work_minutes']} minutes/day\n",
    "- Average Leisure Time: {analytics['avg_leisure_minutes']} minutes/day\n",
    "- Average Sleep Time: {analytics['avg_sleep_minutes']} minutes/day\n",
    "- Average Exercise Time: {analytics['avg_exercise_minutes']} minutes/day\n",
    "- Mean Productivity Score: {analytics['mean_productivity']}\n",
    "\n",
    "SUPERVISOR STATUS:\n",
    "- Confidence Level: {supervisor['confidence']}\n",
    "- Warnings:\n",
    "{warnings_text}\n",
    "\n",
    "INSTRUCTIONS:\n",
    "- Do NOT give medical or absolute advice\n",
    "- Be cautious if confidence is LOW\n",
    "- Explicitly acknowledge uncertainty\n",
    "- Do NOT mention ML models or scores\n",
    "- Keep the tone professional and calm\n",
    "- Respond ONLY in the format below\n",
    "\n",
    "STYLE GUIDELINES:\n",
    "- You may use at most one relevant emoji to improve warmth or clarity\n",
    "- Emoji usage should always remain subtle, professional, and context-aware\n",
    "- When confidence is MEDIUM or HIGH, light emoji use is encouraged if it supports clarity or reassurance\n",
    "- In serious or reflective situations, emojis should be used sparingly and only if they add calm or balance\n",
    "- Avoid playful or energetic emojis in sensitive topics (e.g., fatigue, stress, burnout)\n",
    "- Do not use emojis when confidence is LOW unless they convey calm neutrality\n",
    "- Preferred emojis include: üß† ‚öñÔ∏è üå± ‚è≥\n",
    "- Emojis are optional and should never distract from the message\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "OBSERVATION:\n",
    "REASONING:\n",
    "SUGGESTION:\n",
    "CONFIDENCE NOTE:\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b38aa11f-2dd0-494e-88eb-6b31f5702334",
   "metadata": {},
   "outputs": [],
   "source": [
    "if supervisor_decision[\"status\"] == \"BLOCK\":\n",
    "    print(\"Supervisor blocked reasoning. No LLM response generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb01dbfb-0ab5-422c-aa61-7aadbf9e57a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBSERVATION:\n",
      "Your analytics indicate a substantial dedication to work and learning activities, with an average of 421 minutes per day. Concurrently, there is a reported experience of fatigue, which appears to be in contrast with the observed high output during work periods. Furthermore, there is an indication of potential instability in your productivity patterns.\n",
      "\n",
      "REASONING:\n",
      "The reported fatigue, despite significant work engagement, suggests that the current allocation of time, while productive in output, might be exerting a notable impact on your overall well-being. While your goal of becoming an ML Engineer requires dedicated learning, balancing this with your health priorities is essential for sustained progress. My current analytical insights are limited regarding the specific underlying factors contributing to this fatigue and the perceived productivity instability.\n",
      "\n",
      "SUGGESTION:\n",
      "It may be beneficial to carefully review the intensity and structure of your daily work and learning sessions. Consider assessing how your current routines support both your learning objectives and your health, aligning with your stated priorities. Exploring potential adjustments to your schedule, such as varying work tasks or integrating strategic rest periods, could be a valuable step.\n",
      "\n",
      "CONFIDENCE NOTE:\n",
      "My confidence in comprehensively understanding the precise causes of the reported fatigue and productivity instability is currently low. ‚öñÔ∏è\n"
     ]
    }
   ],
   "source": [
    "if supervisor_decision[\"status\"] == \"ALLOW\":\n",
    "    prompt = build_reasoning_prompt(\n",
    "        user_profile,\n",
    "        analytics_summary,\n",
    "        supervisor_decision\n",
    "    )\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        contents=prompt\n",
    "    )\n",
    "\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf26e2c-23d5-45e5-9d44-9674237e3f69",
   "metadata": {},
   "source": [
    "## LLM Reasoning Summary\n",
    "\n",
    "- Gemini is invoked only after Supervisor approval\n",
    "- Responses are structured and explainable\n",
    "- Emojis are optional and governed by style rules\n",
    "- Confidence level controls tone and caution\n",
    "- LLM acts as a reasoning assistant, not a decision-maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa47dd20-d701-465e-b7b8-2eca9491d76b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
