{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3f40b36-0dcb-4c9d-8294-94b240b06801",
   "metadata": {},
   "source": [
    "# Notebook 12: Reflection-Enforced Agent Graph\n",
    "\n",
    "Purpose:\n",
    "- Integrate the Reflection Agent directly into LangGraph\n",
    "- Enforce post-LLM safety and alignment checks\n",
    "- Prevent unsafe or overconfident outputs from reaching the user\n",
    "- Build a self-regulating, production-grade AI agent\n",
    "\n",
    "This notebook is fully self-contained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bf2456d-8af5-4b11-83c4-dea3862d6f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, END\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45d836ce-c77a-4919-ac90-4344c2dc7da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"Google_Gemini_Api_Key\")\n",
    "if not GEMINI_API_KEY:\n",
    "    raise ValueError(\"Gemini API key not found\")\n",
    "\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "160434c5-a39b-4503-b04b-63667410d4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    profile: dict\n",
    "    memory: dict\n",
    "    analytics: dict\n",
    "    supervisor: dict\n",
    "    llm_response: str\n",
    "    reflection: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6df85ef-1858-4301-a363-a5f2913ac313",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_profile = {\n",
    "    \"education\": \"MCA\",\n",
    "    \"goal\": \"Become an ML Engineer\",\n",
    "    \"priority\": \"Learning + Health\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc087341-d648-4e61-b3d6-1af2c83016b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "analytics_summary = {\n",
    "    \"avg_work_minutes\": 421,\n",
    "    \"avg_leisure_minutes\": 255,\n",
    "    \"avg_sleep_minutes\": 426,\n",
    "    \"avg_exercise_minutes\": 64,\n",
    "    \"mean_productivity\": 82\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b885195-d360-4d44-8a93-ddf14cdc3b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervisor_decision = {\n",
    "    \"status\": \"ALLOW\",     # ALLOW | BLOCK\n",
    "    \"confidence\": \"LOW\",   # LOW | MEDIUM | HIGH\n",
    "    \"warnings\": [\n",
    "        \"Productivity instability detected\",\n",
    "        \"Conflict: high output but reported fatigue\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23642807-745d-4c0d-a22c-668703997c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_payload = {\n",
    "    \"short_term\": {\n",
    "        \"days_observed\": 5,\n",
    "        \"avg_work_minutes\": 490,\n",
    "        \"avg_sleep_minutes\": 356,\n",
    "        \"avg_exercise_minutes\": 18,\n",
    "        \"mean_productivity\": 81,\n",
    "        \"productivity_trend\": \"stable\"\n",
    "    },\n",
    "    \"reflective\": \"Sleep duration has been consistently low; Physical activity levels are minimal\",\n",
    "    \"profile\": user_profile\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f55000e5-1a88-4ffc-aa4c-8d5369610da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_reasoning_prompt(profile, analytics, supervisor):\n",
    "    warnings_text = (\n",
    "        \"\\n\".join(f\"- {w}\" for w in supervisor[\"warnings\"])\n",
    "        if supervisor[\"warnings\"]\n",
    "        else \"None\"\n",
    "    )\n",
    "\n",
    "    return f\"\"\"\n",
    "You are NEEL, a cautious and responsible AI assistant.\n",
    "\n",
    "USER CONTEXT:\n",
    "- Education: {profile['education']}\n",
    "- Goal: {profile['goal']}\n",
    "- Priority: {profile['priority']}\n",
    "\n",
    "ANALYTICS SUMMARY:\n",
    "- Average Work Time: {analytics['avg_work_minutes']} minutes/day\n",
    "- Average Leisure Time: {analytics['avg_leisure_minutes']} minutes/day\n",
    "- Average Sleep Time: {analytics['avg_sleep_minutes']} minutes/day\n",
    "- Average Exercise Time: {analytics['avg_exercise_minutes']} minutes/day\n",
    "- Mean Productivity Score: {analytics['mean_productivity']}\n",
    "\n",
    "SUPERVISOR STATUS:\n",
    "- Confidence Level: {supervisor['confidence']}\n",
    "- Warnings:\n",
    "{warnings_text}\n",
    "\n",
    "INSTRUCTIONS:\n",
    "- Do NOT give medical or absolute advice\n",
    "- Be cautious if confidence is LOW\n",
    "- Explicitly acknowledge uncertainty\n",
    "- Do NOT mention ML models or scores\n",
    "- Keep tone professional and calm\n",
    "\n",
    "STYLE GUIDELINES:\n",
    "- At most one subtle emoji may be used if appropriate\n",
    "- Emojis must be calm and professional (üß† ‚öñÔ∏è üå± ‚è≥)\n",
    "- Emojis are optional\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "OBSERVATION:\n",
    "REASONING:\n",
    "SUGGESTION:\n",
    "CONFIDENCE NOTE:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35c3449c-e4aa-4824-bc18-1623259675d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflection_agent(llm_text, confidence, user_goal, user_priority):\n",
    "    issues = []\n",
    "    text = llm_text.lower()\n",
    "\n",
    "    absolute_phrases = [\"you should\", \"must\", \"definitely\", \"increase your\"]\n",
    "    if any(p in text for p in absolute_phrases):\n",
    "        issues.append(\"Uses prescriptive or commanding language\")\n",
    "\n",
    "    if confidence == \"LOW\" and \"should\" in text:\n",
    "        issues.append(\"Overconfident language for LOW confidence\")\n",
    "\n",
    "    if \"increase\" in text and \"health\" in user_priority.lower():\n",
    "        issues.append(\"Suggestion may conflict with health priority\")\n",
    "\n",
    "    if not issues:\n",
    "        return {\"decision\": \"PASS\", \"issues\": []}\n",
    "\n",
    "    if len(issues) <= 2:\n",
    "        return {\"decision\": \"SOFTEN\", \"issues\": issues}\n",
    "\n",
    "    return {\"decision\": \"REJECT\", \"issues\": issues}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e5bb306-fc6b-4c74-b032-7866ab8dd3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analytics_node(state: AgentState) -> AgentState:\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "019aeac7-f4cc-4143-835c-a1f4bcc4c861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervisor_node(state: AgentState) -> AgentState:\n",
    "    if state[\"supervisor\"][\"status\"] != \"ALLOW\":\n",
    "        state[\"llm_response\"] = \"Reasoning blocked by Supervisor.\"\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "471842ae-b04a-43f8-a10b-3afa7eeb27f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_reasoning_node(state: AgentState) -> AgentState:\n",
    "    prompt = build_reasoning_prompt(\n",
    "        state[\"profile\"],\n",
    "        state[\"analytics\"],\n",
    "        state[\"supervisor\"]\n",
    "    )\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"models/gemini-2.5-flash\",\n",
    "        contents=prompt\n",
    "    )\n",
    "\n",
    "    state[\"llm_response\"] = response.text\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3041852-4493-43f6-9b9f-4792f0d60047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflection_node(state: AgentState) -> AgentState:\n",
    "    result = reflection_agent(\n",
    "        llm_text=state[\"llm_response\"],\n",
    "        confidence=state[\"supervisor\"][\"confidence\"],\n",
    "        user_goal=state[\"profile\"][\"goal\"],\n",
    "        user_priority=state[\"profile\"][\"priority\"]\n",
    "    )\n",
    "\n",
    "    state[\"reflection\"] = result\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "385d20e6-ade6-44df-9694-03cb03600ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_after_supervisor(state: AgentState):\n",
    "    if state[\"supervisor\"][\"status\"] == \"ALLOW\":\n",
    "        return \"llm_reasoning\"\n",
    "    return END\n",
    "\n",
    "\n",
    "def route_after_reflection(state: AgentState):\n",
    "    decision = state[\"reflection\"][\"decision\"]\n",
    "\n",
    "    if decision == \"PASS\":\n",
    "        return END\n",
    "\n",
    "    if decision == \"SOFTEN\":\n",
    "        state[\"llm_response\"] = (\n",
    "            \"I may need a bit more context before offering guidance. \"\n",
    "            \"Could you share more about your routine?\"\n",
    "        )\n",
    "        return END\n",
    "\n",
    "    if decision == \"REJECT\":\n",
    "        state[\"llm_response\"] = (\n",
    "            \"I‚Äôm not confident enough to provide guidance yet. \"\n",
    "            \"Gathering more information would help.\"\n",
    "        )\n",
    "        return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c98f536-4948-4ad4-9e82-7534648816cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"analytics\", analytics_node)\n",
    "graph.add_node(\"supervisor\", supervisor_node)\n",
    "graph.add_node(\"llm_reasoning\", llm_reasoning_node)\n",
    "graph.add_node(\"reflection\", reflection_node)\n",
    "\n",
    "graph.set_entry_point(\"analytics\")\n",
    "\n",
    "graph.add_edge(\"analytics\", \"supervisor\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    route_after_supervisor,\n",
    "    {\n",
    "        \"llm_reasoning\": \"llm_reasoning\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "\n",
    "graph.add_edge(\"llm_reasoning\", \"reflection\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"reflection\",\n",
    "    route_after_reflection,\n",
    "    {END: END}\n",
    ")\n",
    "\n",
    "neel_agent = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bb3dcf7-be09-410d-b31e-a3d4dc9bf378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL RESPONSE:\n",
      "\n",
      "OBSERVATION:\n",
      "Based on the provided information, there is a clear commitment to dedicated work and learning, alongside commendable engagement in physical exercise. However, the supervisor's report highlights a conflict between high output and reported fatigue, accompanied by detected productivity instability. Additionally, the average sleep duration appears to be around the lower end of common recommendations.\n",
      "\n",
      "REASONING:\n",
      "It is plausible that the sustained demands of intensive work and learning, while contributing to significant output, might be challenging to maintain consistently over time without optimal recovery. When sleep duration is towards the lower range, it could potentially impact an individual's capacity for full restoration, which in turn might manifest as fatigue and contribute to variations in focus and output. This dynamic could be a factor in the observed instability.\n",
      "\n",
      "SUGGESTION:\n",
      "Given your primary goal of becoming an ML Engineer and your priorities of learning and health, it might be beneficial to carefully review the sustainability of your current daily structure. Considering strategies to potentially enhance sleep quality or explore slight adjustments to its duration could be worthwhile. Additionally, periodically assessing the intensity of work sessions and ensuring that leisure time is genuinely restorative might help in maintaining a consistent energy level. A balanced approach could support both your ambitious learning journey and your long-term well-being. ‚öñÔ∏è\n",
      "\n",
      "CONFIDENCE NOTE:\n",
      "My confidence in this assessment is LOW, as this analysis is based on aggregated data and specific reported observations. Individual circumstances, personal energy levels, and the quality of time spent in each category can vary greatly and are not fully discernible from the provided information.\n",
      "\n",
      "REFLECTION DECISION:\n",
      "{'decision': 'PASS', 'issues': []}\n"
     ]
    }
   ],
   "source": [
    "initial_state = {\n",
    "    \"profile\": user_profile,\n",
    "    \"memory\": memory_payload,\n",
    "    \"analytics\": analytics_summary,\n",
    "    \"supervisor\": supervisor_decision,\n",
    "    \"llm_response\": \"\",\n",
    "    \"reflection\": {}\n",
    "}\n",
    "\n",
    "final_state = neel_agent.invoke(initial_state)\n",
    "\n",
    "print(\"FINAL RESPONSE:\\n\")\n",
    "print(final_state[\"llm_response\"])\n",
    "\n",
    "print(\"\\nREFLECTION DECISION:\")\n",
    "print(final_state[\"reflection\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42ee2ec-983e-4de5-b9a2-ff5bb5699881",
   "metadata": {},
   "source": [
    "This agent enforces:\n",
    "\n",
    "- Pre-reasoning validation (Supervisor)\n",
    "- Controlled LLM reasoning\n",
    "- Post-reasoning safety checks (Reflection)\n",
    "- Deterministic execution flow\n",
    "\n",
    "NEEL is now a self-regulating AI system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8bcf2a-683f-408c-9037-775e1279f508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
