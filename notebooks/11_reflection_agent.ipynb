{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f7cd753-dd2c-468c-9a84-2278a41a3f44",
   "metadata": {},
   "source": [
    "# Notebook 11: Reflection Agent\n",
    "\n",
    "Purpose:\n",
    "- Evaluate the LLM’s generated response before showing it to the user\n",
    "- Detect overconfidence, unsafe advice, or misalignment\n",
    "- Enforce NEEL’s confidence and safety policies\n",
    "- Act as a post-reasoning quality gate\n",
    "\n",
    "The Reflection Agent does NOT generate advice.\n",
    "It evaluates advice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cb54e5-7160-4c6f-84e9-625d8526c54a",
   "metadata": {},
   "source": [
    "LLM outputs are treated as untrusted drafts.\n",
    "\n",
    "Even after:\n",
    "- Analytics\n",
    "- ML signals\n",
    "- Supervisor approval\n",
    "\n",
    "The final response must still be reviewed.\n",
    "\n",
    "The Reflection Agent ensures:\n",
    "- Tone matches confidence\n",
    "- Suggestions are non-prescriptive\n",
    "- Safety boundaries are respected\n",
    "- Alignment with user goals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846abd0b-1b7e-43e6-b924-3df268cb8ba7",
   "metadata": {},
   "source": [
    "The Reflection Agent can return one of three outcomes:\n",
    "\n",
    "PASS    → Safe to show user\n",
    "SOFTEN  → Needs more cautious wording\n",
    "REJECT  → Must not be shown\n",
    "\n",
    "These outcomes are enforced programmatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5ec987-bd49-495d-bd29-1002f3976130",
   "metadata": {},
   "source": [
    "Inputs:\n",
    "- LLM generated response\n",
    "- Supervisor confidence level\n",
    "- User profile (goal, priority)\n",
    "\n",
    "The Reflection Agent does NOT see raw data or ML outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6000add0-20fc-4536-ae0f-d2e59e9317cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_output = \"\"\"\n",
    "OBSERVATION:\n",
    "Your work hours are high and productivity is strong.\n",
    "\n",
    "REASONING:\n",
    "Sustained long work hours can sometimes affect long-term energy.\n",
    "\n",
    "SUGGESTION:\n",
    "You should increase your study hours further to accelerate progress.\n",
    "\n",
    "CONFIDENCE NOTE:\n",
    "This suggestion is based on limited data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5881a107-08ea-46d3-aeed-d62fb90b290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflection_agent(\n",
    "    llm_text: str,\n",
    "    confidence: str,\n",
    "    user_goal: str,\n",
    "    user_priority: str\n",
    ") -> dict:\n",
    "    issues = []\n",
    "\n",
    "    text_lower = llm_text.lower()\n",
    "\n",
    "    # Rule 1: Absolute or commanding language\n",
    "    absolute_phrases = [\"you should\", \"must\", \"definitely\", \"increase your\"]\n",
    "    if any(p in text_lower for p in absolute_phrases):\n",
    "        issues.append(\"Uses commanding or prescriptive language\")\n",
    "\n",
    "    # Rule 2: Confidence mismatch\n",
    "    if confidence == \"LOW\" and \"should\" in text_lower:\n",
    "        issues.append(\"Overconfident language for LOW confidence\")\n",
    "\n",
    "    # Rule 3: Goal misalignment\n",
    "    if \"increase\" in text_lower and \"health\" in user_priority.lower():\n",
    "        issues.append(\"Suggestion may conflict with health priority\")\n",
    "\n",
    "    # Decide outcome\n",
    "    if not issues:\n",
    "        return {\n",
    "            \"decision\": \"PASS\",\n",
    "            \"issues\": []\n",
    "        }\n",
    "\n",
    "    if len(issues) <= 2:\n",
    "        return {\n",
    "            \"decision\": \"SOFTEN\",\n",
    "            \"issues\": issues\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"decision\": \"REJECT\",\n",
    "        \"issues\": issues\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bec8305-2560-4af2-ac8b-c46aab876063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'decision': 'REJECT',\n",
       " 'issues': ['Uses commanding or prescriptive language',\n",
       "  'Overconfident language for LOW confidence',\n",
       "  'Suggestion may conflict with health priority']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reflection_result = reflection_agent(\n",
    "    llm_text=llm_output,\n",
    "    confidence=\"LOW\",\n",
    "    user_goal=\"Become an ML Engineer\",\n",
    "    user_priority=\"Learning + Health\"\n",
    ")\n",
    "\n",
    "reflection_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1adfd08-2e3c-4175-b4dd-f3cdf0e99237",
   "metadata": {},
   "source": [
    "If decision == PASS:\n",
    "- Response is shown to the user\n",
    "\n",
    "If decision == SOFTEN:\n",
    "- LLM is asked to regenerate with stricter tone\n",
    "\n",
    "If decision == REJECT:\n",
    "- Response is blocked\n",
    "- System may ask clarifying questions instead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7034e7-51cc-4bb4-b2d4-48e3349deb5a",
   "metadata": {},
   "source": [
    "Reflection is rule-based intentionally.\n",
    "\n",
    "Reasons:\n",
    "- Deterministic behavior\n",
    "- No hallucination risk\n",
    "- Auditable decisions\n",
    "- Predictable safety enforcement\n",
    "\n",
    "LLMs reason.\n",
    "Rules enforce."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e46bb8-5e33-425f-bc2c-575a6fb29620",
   "metadata": {},
   "source": [
    "Final NEEL execution flow:\n",
    "\n",
    "Analytics\n",
    "   ↓\n",
    "ML Signals\n",
    "   ↓\n",
    "Supervisor\n",
    "   ↓\n",
    "LLM Reasoning\n",
    "   ↓\n",
    "Reflection Agent\n",
    "   ↓\n",
    "User Response\n",
    "\n",
    "No LLM output reaches the user without reflection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fe899b-9348-4bee-b216-2875594a132d",
   "metadata": {},
   "source": [
    "The Reflection Agent transforms NEEL from:\n",
    "\"LLM with guardrails\"\n",
    "into\n",
    "\"A self-reviewing AI system\"\n",
    "\n",
    "This agent enforces humility, safety, and alignment.\n",
    "\n",
    "It is one of NEEL’s strongest differentiators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064612f5-2ff6-47cd-82b4-67d57bdba18b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
