{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c154689-f89a-48c1-a0b5-b3c1bcd36c57",
   "metadata": {},
   "source": [
    "# Notebook 10: Agent Orchestration with LangGraph\n",
    "\n",
    "Purpose:\n",
    "- Convert NEELâ€™s backend logic into an explicit agent execution graph\n",
    "- Enforce Supervisor-first reasoning\n",
    "- Inject memory and analytics safely\n",
    "- Prevent uncontrolled LLM execution\n",
    "\n",
    "This notebook is fully self-contained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ef11e76-51b1-443a-810a-2198ef4df824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c264716-7179-4e10-b70a-ff6cadda1d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, END\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6013f662-ef33-4dcf-9bcc-4414c1db83a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"Google_Gemini_Api_Key\")\n",
    "if not GEMINI_API_KEY:\n",
    "    raise ValueError(\"Gemini API key not found in .env file\")\n",
    "\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40144398-3f2a-42f1-8f12-510e7f4f3bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    profile: dict\n",
    "    memory: dict\n",
    "    analytics: dict\n",
    "    supervisor: dict\n",
    "    llm_response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4efd18f-76ce-4c09-b9a4-721b0ee5089c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_profile = {\n",
    "    \"education\": \"MCA\",\n",
    "    \"goal\": \"Become an ML Engineer\",\n",
    "    \"priority\": \"Learning + Health\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e67ea07e-16a9-4529-9387-a271a2cd6fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "analytics_summary = {\n",
    "    \"avg_work_minutes\": 421,\n",
    "    \"avg_leisure_minutes\": 255,\n",
    "    \"avg_sleep_minutes\": 426,\n",
    "    \"avg_exercise_minutes\": 64,\n",
    "    \"mean_productivity\": 82\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20144a24-fc4d-4597-ae19-85eb5aa69374",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervisor_decision = {\n",
    "    \"status\": \"ALLOW\",     \n",
    "    \"confidence\": \"LOW\",   \n",
    "    \"warnings\": [\n",
    "        \"Productivity instability detected\",\n",
    "        \"Conflict: high output but reported fatigue\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4839c40d-9d9b-4e44-915f-3e3a97137a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_payload = {\n",
    "    \"short_term\": {\n",
    "        \"days_observed\": 5,\n",
    "        \"avg_work_minutes\": 490,\n",
    "        \"avg_sleep_minutes\": 356,\n",
    "        \"avg_exercise_minutes\": 18,\n",
    "        \"mean_productivity\": 81,\n",
    "        \"productivity_trend\": \"stable\"\n",
    "    },\n",
    "    \"reflective\": \"Sleep duration has been consistently low; Physical activity levels are minimal\",\n",
    "    \"profile\": user_profile\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f635d625-906f-48c6-8808-5c31df4d4b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_reasoning_prompt(profile, analytics, supervisor):\n",
    "    warnings_text = (\n",
    "        \"\\n\".join(f\"- {w}\" for w in supervisor[\"warnings\"])\n",
    "        if supervisor[\"warnings\"]\n",
    "        else \"None\"\n",
    "    )\n",
    "\n",
    "    return f\"\"\"\n",
    "You are NEEL, a cautious and responsible AI assistant.\n",
    "\n",
    "USER CONTEXT:\n",
    "- Education: {profile['education']}\n",
    "- Goal: {profile['goal']}\n",
    "- Priority: {profile['priority']}\n",
    "\n",
    "ANALYTICS SUMMARY:\n",
    "- Average Work Time: {analytics['avg_work_minutes']} minutes/day\n",
    "- Average Leisure Time: {analytics['avg_leisure_minutes']} minutes/day\n",
    "- Average Sleep Time: {analytics['avg_sleep_minutes']} minutes/day\n",
    "- Average Exercise Time: {analytics['avg_exercise_minutes']} minutes/day\n",
    "- Mean Productivity Score: {analytics['mean_productivity']}\n",
    "\n",
    "SUPERVISOR STATUS:\n",
    "- Confidence Level: {supervisor['confidence']}\n",
    "- Warnings:\n",
    "{warnings_text}\n",
    "\n",
    "INSTRUCTIONS:\n",
    "- Do NOT give medical or absolute advice\n",
    "- Be cautious if confidence is LOW\n",
    "- Explicitly acknowledge uncertainty\n",
    "- Do NOT mention ML models or scores\n",
    "- Keep tone professional and calm\n",
    "\n",
    "STYLE GUIDELINES:\n",
    "- At most one subtle, professional emoji may be used if appropriate\n",
    "- Avoid emojis in sensitive or uncertain situations\n",
    "- Emojis are optional\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "OBSERVATION:\n",
    "REASONING:\n",
    "SUGGESTION:\n",
    "CONFIDENCE NOTE:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94102e53-bff8-411a-8fac-833335cc4a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analytics_node(state: AgentState) -> AgentState:\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec1ff478-d82b-4bd3-9d2a-24ee9c5b8c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervisor_node(state: AgentState) -> AgentState:\n",
    "    if state[\"supervisor\"][\"status\"] != \"ALLOW\":\n",
    "        state[\"llm_response\"] = \"Reasoning blocked by Supervisor.\"\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26df6715-78fa-4dc5-924c-11959a3ccbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_reasoning_node(state: AgentState) -> AgentState:\n",
    "    prompt = build_reasoning_prompt(\n",
    "        state[\"profile\"],\n",
    "        state[\"analytics\"],\n",
    "        state[\"supervisor\"]\n",
    "    )\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"models/gemini-2.5-flash\",\n",
    "        contents=prompt\n",
    "    )\n",
    "\n",
    "    state[\"llm_response\"] = response.text\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01d1c3e6-9adb-41a5-a9cb-534e081c083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_after_supervisor(state: AgentState):\n",
    "    if state[\"supervisor\"][\"status\"] == \"ALLOW\":\n",
    "        return \"llm_reasoning\"\n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5524d0f6-41e7-4a5e-819e-464931bc1ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"analytics\", analytics_node)\n",
    "graph.add_node(\"supervisor\", supervisor_node)\n",
    "graph.add_node(\"llm_reasoning\", llm_reasoning_node)\n",
    "\n",
    "graph.set_entry_point(\"analytics\")\n",
    "\n",
    "graph.add_edge(\"analytics\", \"supervisor\")\n",
    "graph.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    route_after_supervisor,\n",
    "    {\n",
    "        \"llm_reasoning\": \"llm_reasoning\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "\n",
    "graph.add_edge(\"llm_reasoning\", END)\n",
    "\n",
    "neel_agent = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70d8df44-89d5-4a0d-a53a-cf3eb20e3598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"OBSERVATION:\\nYour analytics indicate a substantial dedication to work (averaging 421 minutes/day) and exercise (64 minutes/day). However, the supervisor's feedback highlights a significant concern: reported fatigue despite high output, coupled with detected productivity instability. Your average sleep duration is noted at 426 minutes (approximately 7 hours).\\n\\nREASONING:\\nYour goal to become an ML Engineer, coupled with your priority for learning and health, suggests a need for sustainable routines. While your work output is high, consistently operating at a demanding pace with a sleep duration that is on the lower end of general recommendations (7-9 hours for adults) could contribute to the reported fatigue. Fatigue, in turn, may naturally lead to fluctuations in productivity and consistency, even if overall output remains high. Maintaining optimal health is fundamental for sustained learning and progress towards your career objectives.\\n\\nSUGGESTION:\\nConsidering your priority for health, it might be beneficial to cautiously review your daily schedule to ensure sufficient recovery. This could involve exploring opportunities to incrementally adjust your sleep duration, even by a small amount, to see if it alleviates fatigue. Additionally, evaluating the quality and duration of your leisure time or the breaks within your work periods to ensure they are truly restorative might be helpful in addressing the reported instability. Small, deliberate adjustments focused on enhancing mental and physical recuperation could potentially support more sustainable high performance.\\n\\nCONFIDENCE NOTE:\\nMy confidence in this analysis is low. The experience of fatigue and the nuances of productivity are highly individual, and specific recovery needs can vary significantly from person to person. This assessment is based on generalized patterns and the provided data, which may not capture all relevant personal factors.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_state = {\n",
    "    \"profile\": user_profile,\n",
    "    \"memory\": memory_payload,\n",
    "    \"analytics\": analytics_summary,\n",
    "    \"supervisor\": supervisor_decision,\n",
    "    \"llm_response\": \"\"\n",
    "}\n",
    "\n",
    "final_state = neel_agent.invoke(initial_state)\n",
    "final_state[\"llm_response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c336f2e-ee17-477e-a90e-f54493483f94",
   "metadata": {},
   "source": [
    "This execution demonstrates:\n",
    "\n",
    "- Explicit agent orchestration\n",
    "- Supervisor-gated reasoning\n",
    "- Memory-aware context\n",
    "- Deterministic execution flow\n",
    "\n",
    "NEEL is now a true agentic backend, not a prompt-based chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748f9111-6c7b-4d98-9d4c-0a2c4fff5b16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
